{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxM34+Vk3G+Hi6O50bolh4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PbaiX0HXk0_z"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import gym\n","import random\n","import sumolib\n","import traci\n","from collections import deque\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load METR-LA Traffic Dataset\n","def load_data():\n","    df = pd.read_hdf(\"metr-la.h5\")\n","    df.fillna(method='ffill', inplace=True)\n","    return df\n","\n","# Preprocess Data\n","def preprocess_data(df):\n","    scaler = MinMaxScaler()\n","    scaled_data = scaler.fit_transform(df.values)\n","    return scaled_data, scaler\n","\n","# Prepare Data for LSTM\n","def create_sequences(data, seq_length):\n","    X, y = [], []\n","    for i in range(len(data) - seq_length):\n","        X.append(data[i:i+seq_length])\n","        y.append(data[i+seq_length])\n","    return np.array(X), np.array(y)\n","\n","# Define LSTM Model\n","class TrafficLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(TrafficLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h, _ = self.lstm(x)\n","        return self.fc(h[:, -1, :])\n","\n","# Train LSTM Model\n","def train_lstm(X_train, y_train, model, epochs=10, lr=0.001):\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    for epoch in range(epochs):\n","        model.train()\n","        inputs = torch.tensor(X_train, dtype=torch.float32)\n","        targets = torch.tensor(y_train, dtype=torch.float32)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n","\n","# Reinforcement Learning for Traffic Signal Optimization\n","class DQNAgent:\n","    def __init__(self, state_size, action_size):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        self.memory = deque(maxlen=2000)\n","        self.gamma = 0.95  # Discount factor\n","        self.epsilon = 1.0  # Exploration rate\n","        self.epsilon_min = 0.01\n","        self.epsilon_decay = 0.995\n","        self.learning_rate = 0.001\n","        self.model = self._build_model()\n","\n","    def _build_model(self):\n","        model = nn.Sequential(\n","            nn.Linear(self.state_size, 24),\n","            nn.ReLU(),\n","            nn.Linear(24, 24),\n","            nn.ReLU(),\n","            nn.Linear(24, self.action_size)\n","        )\n","        return model\n","\n","    def act(self, state):\n","        if np.random.rand() <= self.epsilon:\n","            return random.randrange(self.action_size)\n","        state = torch.tensor(state, dtype=torch.float32)\n","        act_values = self.model(state)\n","        return torch.argmax(act_values).item()\n","\n","    def remember(self, state, action, reward, next_state, done):\n","        self.memory.append((state, action, reward, next_state, done))\n","\n","    def replay(self, batch_size):\n","        minibatch = random.sample(self.memory, batch_size)\n","        for state, action, reward, next_state, done in minibatch:\n","            target = reward\n","            if not done:\n","                next_state = torch.tensor(next_state, dtype=torch.float32)\n","                target += self.gamma * torch.max(self.model(next_state)).item()\n","            target_f = self.model(torch.tensor(state, dtype=torch.float32))\n","            target_f[action] = target\n","            optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n","            optimizer.zero_grad()\n","            loss = nn.MSELoss()(self.model(torch.tensor(state, dtype=torch.float32)), target_f)\n","            loss.backward()\n","            optimizer.step()\n","        if self.epsilon > self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","# Traffic Simulation with SUMO\n","def run_sumo(agent, episodes=100):\n","    sumo_binary = sumolib.checkBinary('sumo')\n","    for episode in range(episodes):\n","        traci.start([sumo_binary, '-c', 'sumo_config.sumocfg'])\n","        state = np.zeros(agent.state_size)\n","        while traci.simulation.getMinExpectedNumber() > 0:\n","            action = agent.act(state)\n","            reward = -traci.vehicle.getWaitingTime('veh0')\n","            next_state = np.zeros(agent.state_size)\n","            done = False\n","            agent.remember(state, action, reward, next_state, done)\n","            state = next_state\n","        agent.replay(32)\n","        traci.close()\n","\n","# Main Execution\n","if __name__ == \"__main__\":\n","    df = load_data()\n","    scaled_data, scaler = preprocess_data(df)\n","    seq_length = 12\n","    X, y = create_sequences(scaled_data, seq_length)\n","    train_size = int(len(X) * 0.8)\n","    X_train, y_train = X[:train_size], y[:train_size]\n","\n","    lstm_model = TrafficLSTM(input_size=X.shape[2], hidden_size=64, num_layers=2, output_size=1)\n","    train_lstm(X_train, y_train, lstm_model)\n","\n","    agent = DQNAgent(state_size=10, action_size=4)\n","    run_sumo(agent)\n"]}]}